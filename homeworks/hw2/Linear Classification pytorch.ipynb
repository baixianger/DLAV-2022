{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baixianger/DLAV-2022/blob/main/homeworks/hw2/Linear%20Classification%20pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyPbJlzoyA5N"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n",
        "# Linear Classification\n",
        "\n",
        " Implement Linear Classification using pytorch. This consists of having fully connected layers connected one after the other and ReLu activation functions between them.\n",
        " \n",
        " Build a neural network with a minimun of 2 layers in order to do classification."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Permit the notebook to access your drive"
      ],
      "metadata": {
        "id": "Stm2Nhxlso2r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ESXccfIu1H7u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20660f6a-6850-4a71-b59b-931952d08b05"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "whJSL42iyA5S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb26d155-fbe6-4f7a-8a43-1347b151cb0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fd079453cf0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import torch.utils.data as utils\n",
        "import time\n",
        "import pdb\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "torch.manual_seed(1)    # reproducible"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the dataset"
      ],
      "metadata": {
        "id": "zeTqh7pgs0JA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zahsf3gOyA5U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "8963cee5eb9d43109844f4adb3d99050",
            "9fa2cef1a014490c84ff6f97faeb30bb",
            "b7188273b8d6499c955b7f534e27a412",
            "d07f8cad6c0241d3824e87c91e26a6ce",
            "da10545af5174104b64af2c171240a5e",
            "30cebcf33e704f11aee71dbf18616e22",
            "0b43e22e612f4f18a5016766932d7d0a",
            "740539d581f74eb79858b57d8ad2a574",
            "0ca5d6934eee457fb3f348e5b657658a",
            "a9567ccf6cdb439b8ed70fe5595f0c1d",
            "dbff7e822820498b9a0138c5588a5088"
          ]
        },
        "outputId": "2ec40003-f200-4ce9-985f-d2b2da830b2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8963cee5eb9d43109844f4adb3d99050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def get_train_valid_loader(data_dir='../data',\n",
        "                           batch_size=64,\n",
        "                           augment=False,\n",
        "                           random_seed = 1,\n",
        "                           valid_size=0.02,\n",
        "                           shuffle=True,\n",
        "                           show_sample=False,\n",
        "                           num_workers=4,\n",
        "                           pin_memory=False):\n",
        "    \"\"\"\n",
        "    Utility function for loading and returning train and valid\n",
        "    multi-process iterators over the CIFAR-10 dataset. A sample\n",
        "    9x9 grid of the images can be optionally displayed.\n",
        "    If using CUDA, num_workers should be set to 1 and pin_memory to True.\n",
        "    Params\n",
        "    ------\n",
        "    - data_dir: path directory to the dataset.\n",
        "    - batch_size: how many samples per batch to load.\n",
        "    - augment: whether to apply the data augmentation scheme\n",
        "      mentioned in the paper. Only applied on the train split.\n",
        "    - random_seed: fix seed for reproducibility.\n",
        "    - valid_size: percentage split of the training set used for\n",
        "      the validation set. Should be a float in the range [0, 1].\n",
        "    - shuffle: whether to shuffle the train/validation indices.\n",
        "    - show_sample: plot 9x9 sample grid of the dataset.\n",
        "    - num_workers: number of subprocesses to use when loading the dataset.\n",
        "    - pin_memory: whether to copy tensors into CUDA pinned memory. Set it to\n",
        "      True if using GPU.\n",
        "    Returns\n",
        "    -------\n",
        "    - train_loader: training set iterator.\n",
        "    - valid_loader: validation set iterator.\n",
        "    \"\"\"\n",
        "    error_msg = \"[!] valid_size should be in the range [0, 1].\"\n",
        "    assert ((valid_size >= 0) and (valid_size <= 1)), error_msg\n",
        "\n",
        "    normalize = transforms.Normalize(\n",
        "        mean=[0.4914, 0.4822, 0.4465],\n",
        "        std=[0.2023, 0.1994, 0.2010],\n",
        "    )\n",
        "\n",
        "    # define transforms\n",
        "    valid_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "    ])\n",
        "    if augment:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "    else:\n",
        "        train_transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            normalize,\n",
        "        ])\n",
        "\n",
        "    # load the dataset\n",
        "    train_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=train_transform,\n",
        "    )\n",
        "\n",
        "    valid_dataset = datasets.CIFAR10(\n",
        "        root=data_dir, train=True,\n",
        "        download=True, transform=valid_transform,\n",
        "    )\n",
        "\n",
        "    num_train = len(train_dataset)\n",
        "    indices = list(range(num_train))\n",
        "    split = int(np.floor(valid_size * num_train))\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.seed(random_seed)\n",
        "        np.random.shuffle(indices)\n",
        "\n",
        "    train_idx, valid_idx = indices[split:], indices[:split]\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset, batch_size=batch_size, sampler=train_sampler,\n",
        "        num_workers=num_workers, pin_memory=pin_memory,\n",
        "    )\n",
        "    valid_loader = torch.utils.data.DataLoader(\n",
        "        valid_dataset, batch_size=batch_size, sampler=valid_sampler,\n",
        "        num_workers=num_workers, pin_memory=pin_memory,\n",
        "    )\n",
        "\n",
        "    # visualize some images\n",
        "    if show_sample:\n",
        "        sample_loader = torch.utils.data.DataLoader(\n",
        "            train_dataset, batch_size=1, shuffle=shuffle,\n",
        "            num_workers=num_workers, pin_memory=pin_memory,\n",
        "        )\n",
        "        data_iter = iter(sample_loader)\n",
        "        images, labels = data_iter.next()\n",
        "        X = images.numpy().transpose([0, 2, 3, 1])\n",
        "        plot_images(X, labels)\n",
        "\n",
        "    return (train_loader, valid_loader)\n",
        "\n",
        "def plot_images(X, labels):\n",
        "    plt.figure()\n",
        "    plt.imshow(X.squeeze())\n",
        "    plt.axis('off')\n",
        "    plt.title(f'{labels}')\n",
        "\n",
        "trainloader, valloader = get_train_valid_loader(show_sample=True, num_workers=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the network"
      ],
      "metadata": {
        "id": "dr58pZjGs3fF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OYHld_YfyA5Z"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, n_feature, n_hidden, n_output):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Define 2 or more different layers of the neural network                      #\n",
        "        ################################################################################\n",
        "        self.fc1 = torch.nn.Linear(n_feature, n_hidden)\n",
        "        self.fc2 = torch.nn.Linear(n_hidden, n_hidden)\n",
        "        self.fc3 = torch.nn.Linear(n_hidden, n_output)\n",
        "        ################################################################################\n",
        "        #                              END OF YOUR CODE                                #\n",
        "        ################################################################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0),-1)\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Set up the forward pass that the input data will go through.                 #\n",
        "        # A good activation function betweent the layers is a ReLu function.           #\n",
        "        ################################################################################\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        ################################################################################\n",
        "        #                              END OF YOUR CODE                                #\n",
        "        ################################################################################\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "E0ynI2OZyA5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bc7164-2b58-4fbd-b01a-67b174831cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=3072, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "################################################################################\n",
        "# TODO:                                                                        #\n",
        "# Define the parameters of the network the way you want it to be.              #\n",
        "# Choose an Optimizer that will be used to minimize the loss function.         #\n",
        "################################################################################\n",
        "net = Net(n_feature=3*32*32, n_hidden=1024, n_output=10)     # define the network\n",
        "print(net)  # net architecture\n",
        "\n",
        "# Loss and Optimizer (Try different learning rates)\n",
        "# Softmax is internally computed.\n",
        "# Set parameters to be updated. \n",
        "\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr = 0.01)  # Choose the optimizer you want and tune its hyperparameter\n",
        "loss_func = torch.nn.CrossEntropyLoss()  # the target label is NOT an one-hotted\n",
        "################################################################################\n",
        "#                              END OF YOUR CODE                                #\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FBUs_zOVyA5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "6d2671c1-7a73-413d-860f-a492f8039a45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tAccuracy of the network on the 1000 val images:                     32 %\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b07ab8bc2f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#traindataset = utils.TensorDataset(X_train, y_train)\n",
        "#trainloader = utils.DataLoader(traindataset, batch_size=64, shuffle=True)\n",
        "\n",
        "epochs = 50\n",
        "steps = 0\n",
        "print_every = 100\n",
        "for e in range(epochs):\n",
        "    start = time.time()\n",
        "    print(f'Epoch{e:2d}/{epochs}')\n",
        "    for images, labels in iter(trainloader):\n",
        "        steps += 1\n",
        "        ################################################################################\n",
        "        # TODO:                                                                        #\n",
        "        # Run the training process                                                     #\n",
        "        #                                                                              #\n",
        "        ################################################################################\n",
        "        images.resize_(images.size()[0], 3*32*32)\n",
        "        optimizer.zero_grad()\n",
        "        output = net(images)\n",
        "        loss = loss_func(output, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        ################################################################################\n",
        "        #                              END OF YOUR CODE                                #\n",
        "        ################################################################################\n",
        "    \n",
        "        if steps % print_every == 0:\n",
        "                stop = time.time()\n",
        "                # Test accuracy\n",
        "                net.eval()\n",
        "                correct = 0\n",
        "                total = 0\n",
        "                with torch.no_grad():\n",
        "                    for data in valloader:\n",
        "                          images, labels = data\n",
        "                          outputs = net(images)\n",
        "                          _, predicted = torch.max(F.softmax(outputs).data, 1)\n",
        "                          total += labels.size(0)\n",
        "                          correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    print('\\tAccuracy of the network on the %d val images: \\\n",
        "                    %d %%' % (total,100 * correct / total))\n",
        "\n",
        "                start = time.time()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gx02lf4yA5c"
      },
      "source": [
        "After training, the model should be saved to be tested on the test dataset or to be used in a real-life application. To save your model in pytorch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cTzmX0nZyA5c"
      },
      "outputs": [],
      "source": [
        "torch.save(net.state_dict(), 'drive/MyDrive/Colab Notebooks/linearClassifier_pytorch.ckpt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdGRq6H7yA5d"
      },
      "source": [
        "Remeber the above path. You need to load your trained model in another notebook:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y0q1qkYsyA5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f913067f-4c0e-43c4-a1d4-e82497e8560c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "checkpoint = torch.load(\"drive/MyDrive/Colab Notebooks/linearClassifier_pytorch.ckpt\")\n",
        "net.load_state_dict(checkpoint)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "nteract": {
      "version": "0.12.3"
    },
    "colab": {
      "name": "Linear Classification pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8963cee5eb9d43109844f4adb3d99050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9fa2cef1a014490c84ff6f97faeb30bb",
              "IPY_MODEL_b7188273b8d6499c955b7f534e27a412",
              "IPY_MODEL_d07f8cad6c0241d3824e87c91e26a6ce"
            ],
            "layout": "IPY_MODEL_da10545af5174104b64af2c171240a5e"
          }
        },
        "9fa2cef1a014490c84ff6f97faeb30bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30cebcf33e704f11aee71dbf18616e22",
            "placeholder": "​",
            "style": "IPY_MODEL_0b43e22e612f4f18a5016766932d7d0a",
            "value": ""
          }
        },
        "b7188273b8d6499c955b7f534e27a412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_740539d581f74eb79858b57d8ad2a574",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ca5d6934eee457fb3f348e5b657658a",
            "value": 170498071
          }
        },
        "d07f8cad6c0241d3824e87c91e26a6ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9567ccf6cdb439b8ed70fe5595f0c1d",
            "placeholder": "​",
            "style": "IPY_MODEL_dbff7e822820498b9a0138c5588a5088",
            "value": " 170499072/? [00:02&lt;00:00, 61406013.21it/s]"
          }
        },
        "da10545af5174104b64af2c171240a5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30cebcf33e704f11aee71dbf18616e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b43e22e612f4f18a5016766932d7d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "740539d581f74eb79858b57d8ad2a574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ca5d6934eee457fb3f348e5b657658a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a9567ccf6cdb439b8ed70fe5595f0c1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbff7e822820498b9a0138c5588a5088": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}